---
title: Batch Normalization
comments: true
categories: research
---
<center><img src="assets/191017-BatchNormaliztion/bn.png" width="80%"></center>    

**학습**시에는 미니배치에서 평균과 표준편차를 구한다. 이를 이용해 정규화 한 후 Scale Factor(gamma)와 Shift Factor(beta)로 새로운 값을 활성화 함수에 넣는다.  

**테스트**시에는 학습 할 때 저장한 이동평균(moving average) 및 Unbiased variance estimate의 이동평균을 계산하여 저장해 놓은 뒤 정규화 해 놓는다(?)

[Reference]
https://shuuki4.wordpress.com/2016/01/13/batch-normalization-%ec%84%a4%eb%aa%85-%eb%b0%8f-%ea%b5%ac%ed%98%84/#comments
